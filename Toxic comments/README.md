# Toxic comments 
<b>Статус проекта</b> Завершен

<b>Цели проекта</b>

•	Создать модель, определяющую, токсичен ли комментарий или нет. Оценить ее по критерию качества f1.

<b>Задачи проекта</b>

1.	Предобработка Данных 

-	Лемматизация с помощью spacy

-	Удаление лишних символов

-	Удаление стоп-слов (nltk)

-	Векторизация корпуса с помощью TfidfVectorizer

2.	Обучение моделей 

-	Logistic Regression
-	Decision Tree

3.	Анализ результатов предсказаний

<b>Итоги</b>

В данном проекте мы подобрали модель, определяющую, токсичен ли комментарий или нет. У нас был датасэт с комментариями и меткой.

На этапе предобработки мы леммитизировали текст и привели данные к векторному виду.

На этапе обучения мы рассмотрели несколько моделей:

- DecisionTree
- LogisticRegression

Лучший результат показала логистическая регрессия = 0.75.

<b>Используемый стек инструментов</b>

• python • pandas • sklearn • DecisionTree • LogisticRegression • tqdm • f1 score • nltk • TfidfVectorizer • spacy 
